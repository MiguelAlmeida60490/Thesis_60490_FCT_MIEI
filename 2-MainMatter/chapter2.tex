%!TEX root = ../template.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% chapter2.tex
%% NOVA thesis document file
%%
%% Chapter with the template manual
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\typeout{NT FILE chapter2.tex}%

\chapter{Conceitos}\label{cha:conceitos}

Este capítulo tem como objetivo apresentar os principais conceitos teóricos e técnicos que sustentam o desenvolvimento desta dissertação. São abordados os fundamentos relacionados com o processo de \gls{CR} no contexto do desenvolvimento de \textit{software}, bem como a evolução das abordagens de automação aplicadas a este processo.

\section{\textit{Code Review} no Desenvolvimento de \textit{Software}}

\gls{CR} é uma prática fundamental no desenvolvimento de software que consiste na análise sistemática do código-fonte por um ou mais programadores, com o objetivo de identificar defeitos, melhorar a qualidade do código e garantir a conformidade com boas práticas e padrões definidos pela organização~\cite{bacchelli2013expectations,rigby2013convergent}. Esta atividade é normalmente realizada antes da integração de alterações no ramo principal do projeto, assumindo um papel central nos fluxos de desenvolvimento modernos baseados em \glspl{PR}.

Historicamente, a revisão de código surgiu como uma prática formal, associada a inspeções estruturadas, como as inspeções de Fagan, que demonstraram benefícios significativos na deteção precoce de erros e na redução de custos associados à correção de defeitos em fases avançadas do desenvolvimento~\cite{fagan1976design}. Com a evolução das metodologias ágeis e das plataformas colaborativas de desenvolvimento, a revisão de código tornou-se um processo mais leve e contínuo, integrado no ciclo diário de desenvolvimento de software~\cite{rigby2013convergent}.

Os principais objetivos da revisão de código incluem a deteção de erros lógicos e defeitos funcionais, a melhoria da legibilidade e manutenibilidade do código, a verificação da conformidade com padrões de estilo e boas práticas, bem como a mitigação de riscos relacionados com segurança e desempenho~\cite{mcintosh2014empirical}. Para além dos aspetos técnicos, a revisão de código desempenha também um papel relevante na partilha de conhecimento entre membros da equipa, promovendo a disseminação de boas práticas e contribuindo para a uniformização do código ao longo do projeto~\cite{bacchelli2013expectations}.

Apesar dos seus benefícios comprovados, a revisão de código é uma atividade exigente do ponto de vista cognitivo e temporal, dependendo fortemente da experiência e disponibilidade dos revisores. Em projetos de grande escala, caracterizados por elevados volumes de alterações e diversidade tecnológica, este processo pode tornar-se difícil de escalar, originando atrasos, inconsistências e variabilidade na qualidade das revisões realizadas~\cite{bacchelli2013expectations,mcintosh2014empirical}.

\section{Automação do Processo de \textit{Code Review}}

Com o aumento da complexidade dos sistemas de software e do volume de alterações submetidas diariamente, surgiu a necessidade de melhorar o processo de \gls{CR} através de mecanismos de automação. O principal objetivo destas abordagens é reduzir o esforço manual associado a tarefas repetitivas, melhorar a deteção precoce de defeitos e apoiar os revisores humanos na análise das alterações de código~\cite{bacchelli2013expectations}.

As primeiras tentativas de automação do \gls{CR} basearam-se essencialmente em ferramentas de análise estática de código. Estas ferramentas analisam o código-fonte sem necessidade de execução, recorrendo a regras pré-definidas para identificar problemas como violações de estilo, padrões perigosos, possíveis erros de execução ou más práticas comuns~\cite{liang2024automation}. Linters e analisadores estáticos tornaram-se parte integrante dos fluxos de desenvolvimento modernos, sendo frequentemente integrados em pipelines de \gls{CI}.

Apesar dos benefícios associados à sua utilização, estas abordagens apresentam limitações significativas. Estudos mostram que ferramentas de análise estática tendem a gerar um elevado número de falsos positivos, o que pode levar à sua desvalorização por parte dos programadores~\cite{johnson2013donotuse}. Além disso, estas ferramentas possuem uma compreensão limitada do contexto em que o código é desenvolvido, não conseguindo capturar a intenção do programador, decisões de design ou requisitos específicos do domínio da aplicação~\cite{kim2016warnings}.

Outra limitação relevante prende-se com a rigidez das regras utilizadas. A adaptação destas ferramentas a práticas internas ou a estilos específicos de uma organização requer frequentemente configurações manuais complexas, dificultando a sua adoção em ambientes empresariais com grande diversidade tecnológica~\cite{liang2024automation}. Como consequência, a automação tradicional do \gls{CR} tende a ser eficaz na deteção de problemas simples e bem definidos, mas menos adequada para identificar defeitos mais complexos ou fornecer comentários contextualizados e acionáveis.

Estas limitações motivaram a investigação de abordagens mais avançadas para a automação do processo de revisão de código, explorando técnicas de \gls{ML} capazes de aprender padrões diretamente a partir de grandes volumes de código-fonte e dados históricos de desenvolvimento~\cite{allamanis2018survey}. Estas abordagens abriram caminho para soluções mais flexíveis e contextuais, que serão discutidas nas secções seguintes.

\section{Aprendizagem Automática e \textit{Deep Learning} em \textit{Code Review}}

As limitações das abordagens tradicionais de automação do \gls{CR} motivaram a utilização de técnicas de \gls{ML} e, posteriormente, de \gls{DL}. Ao contrário das ferramentas baseadas em regras fixas, estas abordagens permitem aprender padrões diretamente a partir de grandes volumes de código-fonte e dados históricos de desenvolvimento, reduzindo a necessidade de configuração manual e aumentando a capacidade de generalização~\cite{allamanis2018survey}.

Os primeiros trabalhos nesta área exploraram modelos estatísticos e técnicas de aprendizagem supervisionada para identificar padrões de defeitos, prever a probabilidade de erros e priorizar avisos gerados por ferramentas automáticas~\cite{kim2016warnings}. Estas abordagens demonstraram que informação histórica, como alterações anteriores e decisões tomadas em revisões passadas, pode ser utilizada para melhorar a eficácia do processo de \gls{CR}.

Com o avanço de técnicas de \gls{DL}, surgiram modelos capazes de representar o código-fonte de forma mais expressiva, explorando a sua estrutura sintática e semântica. Trabalhos baseados em redes neuronais profundas passaram a utilizar representações como \gls{AST}, grafos de fluxo de controlo e sequências de \textit{tokens}, permitindo capturar relações mais complexas entre diferentes componentes do código base~\cite{tufano2019deeplearning}. Estes modelos mostram melhorias significativas em tarefas como deteção de defeitos, sugestões de correções e identificação de padrões recorrentes no código.

Outro avanço relevante foi a introdução do conceito de \textit{naturalness} do software, que assume que o código-fonte apresenta regularidades semelhantes às da linguagem natural. Estudos demonstraram que código que se desvia destes padrões tende a estar mais associado a defeitos, o que abriu caminho à aplicação de \gls{NLP} à análise de código~\cite{hindle2012naturalness}. Esta perspetiva reforçou a adequação de técnicas originalmente desenvolvidas para processamento de linguagem natural ao domínio do desenvolvimento de software.

Apesar dos progressos alcançados, as abordagens baseadas em \gls{ML} e \gls{DL} apresentavam ainda algumas limitações práticas. Muitos modelos exigiam grandes volumes de dados rotulados, eram dispendiosos do ponto de vista computacional e apresentavam dificuldades em lidar com múltiplas linguagens de programação ou contextos organizacionais específicos~\cite{allamanis2018survey}. Além disso, a integração destas soluções nos fluxos de desenvolvimento reais permanecia um desafio.

Estas limitações criaram as condições para a adoção de \glspl{LLM}, capazes de aprender representações genéricas de código e de transferir conhecimento entre diferentes tarefas e linguagens. A utilização de \glspl{LLM} no processo de \gls{CR} será abordada na secção seguinte.

\section{Modelos de Linguagem de Grande Escala}

Os \glspl{LLM} representam a evolução mais recente no campo da aprendizagem profunda aplicada à linguagem. São modelos baseados na arquitetura \textit{Transformer}, treinados com grandes quantidades de dados textuais e, no contexto relevante para esta dissertação, também em código-fonte, que adquiriram capacidades generativas e de compreensão contextual notáveis~\cite{vaswani2017attention, llmsurvey2023}.

Ao contrário dos modelos anteriores de \gls{DL} em que é necessário algum tipo de calibração ou ajustes específicos para cada tarefa, os \glspl{LLM} modernos não necessitam de tanta informação ou exemplos para conseguir devolver uma resposta. Isto significa que podem realizar novas tarefas com base apenas em instruções de linguagem natural, sem necessidade de treino adicional extensivo~\cite{brown2020gpt3}. Esta característica é fundamental para a sua aplicação prática em ambientes empresariais, onde a diversidade de tarefas e a necessidade de rápida adaptação são elevadas.

Dois aspetos tornam os \glspl{LLM} particularmente adequados para a análise de código:
\begin{enumerate}
    \item \textbf{Treino Multimodal (Texto e Código):} Modelos como o Codex (base do GitHub Copilot), o GPT-4, ou modelos \textit{open-source} como o CodeLLaMA, foram treinados em vastos \textit{corpora} que incluem tanto linguagem natural como código-fonte de múltiplas linguagens de programação. Isto permitiu-lhes aprender não só a sintaxe, mas também padrões semânticos, \textit{idioms} comuns e até associações entre comentários (especificações em linguagem natural) e a sua implementação~\cite{llmsurvey2023, tufano2024slr}.
    \item \textbf{Compreensão de Contexto de Longo Alcance:} A arquitetura \textit{Transformer}, através do seu mecanismo de \textit{attention}, permite que o modelo pondere relações entre \textit{tokens} distantes no texto de entrada. Isto é crucial para compreender um \gls{Diff} de código, onde uma alteração numa linha pode ter implicações em funções ou módulos referenciados noutras partes do ficheiro~\cite{vaswani2017attention}.
\end{enumerate}

Estas capacidades transformam os \glspl{LLM} de meros geradores de texto em ferramentas potencialmente capazes de atuar como \textit{assistentes de programação inteligentes}, compreendendo a intenção por trás de alterações de código e avaliando-as num contexto mais amplo do que as ferramentas de análise estática baseadas em regras.

\section{Modelos de Linguagem de Grande Escala Aplicados à Revisão de Código}

A aplicação de \glspl{LLM} à automação da revisão de código é uma área de investigação e desenvolvimento industrial em rápido crescimento. Estes modelos são utilizados para automatizar ou auxiliar várias sub-tarefas do processo de \gls{CR}:

\begin{itemize}
    \item \textbf{Geração de Descrições e Sumários:} Automatizar a criação de descrições concisas para \glspl{PR}, resumindo as alterações realizadas, o que ajuda os revisores a compreender rapidamente o contexto~\cite{codeagent2024}.
    \item \textbf{Deteção de Defeitos e \textit{Code Smells}:} Identificar potenciais \textit{bugs}, vulnerabilidades de segurança, más práticas de desempenho ou violações de princípios de design (como SOLID) com base no contexto aprendido, superando em alguns casos a precisão de analisadores estáticos tradicionais para certos tipos de problemas~\cite{liang2024automation}.
    \item \textbf{Geração de Comentários de Revisão:} Esta é a aplicação mais diretamente relacionada com o objetivo desta dissertação. Os \glspl{LLM} analisam o \gls{Diff} e geram comentários que podem variar desde sugestões de estilo (formatação, nomenclatura) até a questões de lógica, sugerindo implementações alternativas ou apontando casos extremos não tratados~\cite{airesults2024review, google2024autocommenter}.
    \item \textbf{Resposta a Comentários:} Alguns sistemas exploram a capacidade dos \glspl{LLM} de atuar como autores, respondendo automaticamente a comentários dos revisores, esclarecendo decisões ou comprometendo-se com correções~\cite{codeagent2024}.
\end{itemize}

\textbf{Estudos e Resultados Chave:} Trabalhos recentes demonstram o potencial desta abordagem. Por exemplo, estudos que utilizam modelos como o GPT-3.5/4 ou o CodeLLaMA mostraram que os comentários gerados podem ser considerados úteis por programadores numa percentagem significativa dos casos, por vezes equivalentes a comentários de revisores humanos para categorias específicas de problemas~\cite{liang2024automation}. No entanto, a literatura também aponta desafios consistentes: a utilidade é altamente variável, há uma tendência para gerar falsos positivos ou sugestões genéricas, e os modelos podem ``alucinar'', sugerindo problemas inexistentes ou correções incorretas~\cite{liang2024automation, jiang2023codereview}.

A eficácia destes sistemas depende criticamente da formulação do \textit{prompt} (a instrução dada ao modelo), do contexto fornecido (o \gls{Diff}, mas também potencialmente ficheiros relevantes, descrição do \gls{PR}, etc.) e da existência de um mecanismo para guiar o modelo com o conhecimento específico da organização \-- uma lacuna que esta dissertação pretende colmatar.

\section{Limitações atuais e Desafios}

Apesar do potencial demonstrado, a integração prática de \glspl{LLM} no processo de \gls{CR} em ambientes empresariais específicos, como o da Processware, enfrenta vários desafios significativos:

\begin{enumerate}
    \item \textbf{Falta de Contexto Organizacional Específico:} \glspl{LLM} genéricos são treinados em código público e conhecimentos gerais. Não possuem conhecimento inerente sobre as \textbf{boas práticas internas}, convenções de \textit{codebase}, padrões de arquitetura específicos ou regras de negócio de uma empresa. Um comentário genericamente correto pode ser irrelevante ou mesmo contrário aos padrões internos da organização~\cite{google2024autocommenter, tufano2024slr}.
    \item \textbf{Variabilidade e Inconsistência na Qualidade:} A utilidade dos comentários gerados pode flutuar amplamente. O modelo pode produzir uma análise perspicaz num caso e, no seguinte, gerar comentários vagos, incorretos ou focados em aspetos triviais, minando a confiança dos programadores~\cite{liang2024automation}.
    \item \textbf{Alucinações e Falsos Positivos:} \glspl{LLM} podem identificar ``problemas'' que não existem, sugerir correções sintaticamente inválidas ou semanticamente erradas, ou atribuir incorretamente a causa de um defeito. Esta falta de fiabilidade exige uma supervisão humana cuidadosa, podendo anular os ganhos de eficiência~\cite{jiang2023codereview}.
    \item \textbf{Custo e Latência:} A execução de \glspl{LLM} de grande porte para analisar cada \gls{PR} pode ter custos computacionais e financeiros não triviais, além de introduzir latência no processo, especialmente para \glspl{Diff} grandes ou análises complexas.
    \item \textbf{Integração no Fluxo de Trabalho (\textit{Workflow}):} Incorporar uma ferramenta baseada em \glspl{LLM} de forma não intrusiva e que realmente agregue valor \-- em vez de gerar ruído \-- é um desafio de engenharia. A ferramenta deve complementar, e não substituir ou atrapalhar, o julgamento humano e a dinâmica colaborativa da revisão.
\end{enumerate}

Este conjunto de limitações define claramente o espaço para a contribuição proposta nesta dissertação. O problema central não é \textit{se} os \glspl{LLM} podem gerar comentários, mas \textbf{como fazê-lo de forma consistente, alinhada com o contexto específico da Processware, e suficientemente fiável para ser integrada no fluxo de desenvolvimento da empresa}. A solução proposta, ao focar-se na personalização com base nas boas práticas internas e na integração fluida, aborda diretamente as lacunas 1 e 5, enquanto os objetivos de avaliação (Objetivo 5) visam mitigar os riscos apontados nas lacunas 2, 3 e 4.
